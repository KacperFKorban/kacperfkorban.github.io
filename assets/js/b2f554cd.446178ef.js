"use strict";(self.webpackChunkkacperfkorban_github_io=self.webpackChunkkacperfkorban_github_io||[]).push([[477],{10:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"Data Modeling in Scala 3, but I only use types","metadata":{"permalink":"/blog/Data Modeling in Scala 3, but I only use types","editUrl":"https://github.com/KacperFKorban/kacperfkorban.github.io/blog/2022-06-06-Data-Modeling-in-Scala-3-but-I-only-use-types.md","source":"@site/blog/2022-06-06-Data-Modeling-in-Scala-3-but-I-only-use-types.md","title":"Data Modeling in Scala 3, but I only use types","description":"That\u2019s the whole idea.","date":"2022-06-06T00:00:00.000Z","formattedDate":"June 6, 2022","tags":[{"label":"scala","permalink":"/blog/tags/scala"},{"label":"scala 3","permalink":"/blog/tags/scala-3"}],"readingTime":7.46,"truncated":false,"authors":[{"name":"Kacper Korban","url":"https://github.com/KacperFKorban","imageURL":"https://avatars.githubusercontent.com/u/39772805?v=4","key":"k\u03c0"}],"nextItem":{"title":"Achieving Indisputable Job Security Using Novel Scala 3 Features: A Case Study","permalink":"/blog/Achieving-Indisputable-Job-Security-Using-Novel-Scala-3-Features-A-Case-Study"}},"content":"That\u2019s the whole idea.\\n\\nWe want to model data in Scala, but instead of using instances of classes at the term level, we want to use their type-constructors at the type level.\\n\\n## Recruitment system\\n\\nLet\u2019s pick an example to help us visualize the whole process better, because just like a wise person once said \u201cA picture is worth a thousand words\u201d.\\n\\nWe will represent candidate profiles in a recruitment process for software engineering companies. Let\u2019s start with the term model code and I\u2019ll walk you through it.\\n\\n```scala\\ncase class Candidate(\\n  name: String,\\n  experience: List[Experience],\\n  otherQualities: List[String]\\n)\\n\\ncase class Experience(\\n  duration: Int,\\n  expLevel: ExpLevel,\\n  company: String,\\n  technologies: List[String]\\n)\\n\\nenum ExpLevel:\\n  case Junior\\n  case Regular\\n  case Senior\\n  case CEO\\nexport ExpLevel.*\\n```\\n\\nWe can represent candidates by providing their:\\n- name \u2013 just a String\\n- experience history \u2013 list of Experience entries\\n- other qualities \u2013 list of string\\n\\nAnd experience entry is represented by:\\n- duration \u2013 number of months at the job\\n- experience level \u2013 enum value representing experience levels in IT\\n- company name \u2013 a String\\n- technologies \u2013 list of technologies used\\n\\nSo if we were to create a very simplified profile using our model, it will look like this.\\n\\n```scala\\nval candidate = Candidate(\\n  \\"John Paul\\",\\n  Experience(\\n    29,\\n    Junior,\\n    \\"VirtusLab\\",\\n   \\"Scala\\" :: Nil\\n  ) :: Nil,\\n  \\"Motivated\\" :: Nil\\n)\\n```\\n\\nCool, nothing new so far.\\n\\n## Making it spicier\\n\\nThat was some basic Scala. Now what we want to do: is to be able to have all this information on the type level.\\n\\nYou might be asking: We already declared a model in the previous section. Can\u2019t we just use that one?\\nAs expected, the answer is: No. That\u2019s because Scala distinguishes terms from types. The previous model worked on the term level, and we want to do it on the type level. So, we will have to tweak it a bit.\\n\\nTo make our intentions 100% clear, we want to be able to declare a type like the following (or at least similar).\\n\\n```scala\\ntype candidate = Candidate[\\n  \\"John Paul\\",\\n  Experience[\\n    29,\\n    Junior,\\n    \\"VirtusLab\\",\\n    \\"Scala\\" :: Nil\\n  ] :: Nil,\\n  \\"Motivated\\" :: Nil\\n]\\n```\\n\\nLet\u2019s start our work with the most basic class and work our way up the dependency graph.\\n\\n### Experience level\\n\\nFirst, let\u2019s look at **ExpLevel**. We declared it before as\\n\\n```scala\\nenum ExpLevel:\\n  case Junior\\n  case Regular\\n  case Senior\\n  case CEO\\nexport ExpLevel.*\\n```\\n\\nWhen we think about it, its type constructors carry the same amount of information as its data constructors, so we could leave it as it is.\\nThere is a small problem with the current declaration though. When we want to access the type of `Junior` and use it as e.g. a type parameter for `List`, we cannot just say `List[Junior]`. That\u2019s because there is no such type constructor as `Junior`. Instead, we will have to type `List[Junior.type]`. This can be quite annoying, specifically when it\u2019s a part of the interface exposed to the user.\\nIs there a way to fix it then? Yes, and it\u2019s actually quite simple. Just like by writing in Python I can force myself into a crippling depression, you can force Scala to generate classes for all our cases by just adding parentheses after the constructors. Then, those won\u2019t just be values, but classes with empty constructors.\\n\\n```scala\\nenum ExpLevel:\\n  case Junior()\\n  case Regular()\\n  case Senior()\\n  case CEO()\\nexport ExpLevel.*\\n```\\n\\nNice, on to the next one.\\n\\n### Experience\\n\\nNow that we fixed the `ExpLevel` data type, let\u2019s move on to Experience. In the term model, it looked like this\\n\\n```scala\\ncase class Experience(\\n  duration: Int,\\n  expLevel: ExpLevel,\\n  company: String,\\n  technologies: List[String]\\n)\\n```\\n\\nWe want all of those term parameters to become type parameters, so let\u2019s try just adding them.\\nThe strategy will be, for every term parameter we will:\\n1. create a type parameter with the same name\\n2. add a type constraint for it using <: operator\\n\\nIt is important that we use <: here and not :. That is because, when used on types, the first one is semantically equivalent to \u201cis subtype of\u201d and the latter means \u201chas implicit instance of\u201d.\\nLet\u2019s take a look at the result of our transformation then.\\n\\n```scala\\ncase class Experience[\\n  duration <: Int,\\n  expLevel <: ExpLevel,\\n  company <: String,\\n  technologies <: List[String]\\n]()\\n```\\n\\nAt first glance, it looks ok and it looks very similar to the term model. We have an entry for every parameter and the constraints are the same as before. But does it work? Well, no. If I were to play the role of a build tool, I would say that we have one warning and one error.\\n\\nLet\u2019s start with the warning. Take a look at this class and think, what does the `case` keyword give us here. Well, it gives us the `apply` function to our empty constructor, `getters` to our non-existent fields, the `unapply` function for a class we will never construct, and some other extremely useful methods.\\nDo you get the point? The `case` keyword here is just as useful as a cats-effect expert at Ziverge.\\n\\nCool. On to the error now. This one might not be as easy to spot. To make it easier, let\u2019s look at how List is implemented. Skipping a lot of details, we have:\\n\\n```scala\\nsealed abstract class List[+A]\\nfinal case class :: [+A](head: A, next: List[A]) extends List[A]\\ncase object Nil extends List[Nothing]\\n```\\n\\nWe have a supertype `List` and two type constructors `::` (cons) and `Nil`.\\n`Nil`, carries no information since it just symbolizes an empty list. No problem here.\\nBut, when we take a look at `::`, it only has one type parameter. This would mean that it will only be able to carry the definition of one `String`.\\n\\nLet\u2019s create our own data structure then. To make it easier, it should only contain `String`s.\\n\\n```scala\\nsealed trait StrList\\nclass Nl extends StrList\\nclass :|:[head <: String, tail <: StrList] extends StrList\\n```\\n\\nVoila. We just take a look at the definition of List and move every term parameter to type-level, like before.\\n\\nIf we put all the parts together, we get.\\n\\n```scala\\nclass Experience[\\n  duration <: Int,\\n  expLevel <: ExpLevel,\\n  company <: String,\\n  technologies <: StrList\\n]\\n```\\n\\n### Candidate\\n\\nLet\u2019s take a look at our last class \u2013 `Candidate`.\\n\\n```scala\\ncase class Candidate(\\n  name: String,\\n  experience: List[Experience],\\n  otherQualities: List[String]\\n)\\n```\\n\\nRight off the bat, we can spot similar problems as with `Experience` \u2013 Lists. Fortunately, we already have a structure for type-level lists of Strings from before. This means that we just need lists of `Experience`s. We can declare it in a similar way as with lists of strings, right? Let\u2019s try.\\n\\n```scala\\nsealed trait Experiences\\nclass Empty extends Experiences\\nclass :+:[head <: ???, tail <: Experiences] extends Experiences\\n```\\n\\nOk. This looks exactly like the `StrList` with some minor name changes. Why is there a question mark instead of the constraint of head? That\u2019s because we cannot use `Experience` there. `Experience` is a type constructor that takes a non-empty parameter list. We would have to specify it on the spot.\\n\\nIs there some trick we can use here? Or is Scala\u2019s type system not expressive enough?\\nOf course, there is a workaround. It is also quite a common pattern. It\u2019s every functional programmer\u2019s biggest nightmare and every object-oriented programmer\u2019s wet dream: `Inheritance`.\\n\\nIf we add a supertype to our `Experience` class, we can use it in every place where we would usually use a type and treat `Experience` as the implementation.\\n\\n```scala\\nsealed trait Exp\\nclass Experience[\\n  ...\\n] extends Exp\\n```\\n\\nIs this solution pretty? No.\\nBut as the tapeworm said: There was no other way.\\n\\nNow that we have fixed this issue, there is nothing interesting anymore with transforming the `Candidate` class.\\n\\n```scala\\nclass Candidate[\\n  name <: String,\\n  experience <: Experiences,\\n  otherQualities <: StrList\\n]\\n```\\n\\n## Final form\\n\\nAfter all that work we can finally write our correct example instance.\\n\\n```scala\\ntype mystery = Candidate[\\n  \\"John Paul\\",\\n  Experience[\\n    29,\\n    Junior,\\n    \\"VirtusLab\\",\\n    \\"Scala\\" :|: Nl\\n  ] :+: Empty,\\n  \\"Motivated\\" :|: Nl\\n]\\n```\\n\\nAnd it compiles, which means that it works!\\n\\n## C\'mon, Do Something\\n\\nNow, you\u2019re probably thinking: \u201cCool, we can model data now but there is more to computer systems than just data.\u201d There is always some domain logic that needs to be implemented. In our case, we should definitely add some sanity checks. Like removing any experience in Rust and adding a \u201cGood sense of humor\u201d quality instead.\\n\\nCan we do that? Yes, but since this blog post is already longer than the documentation for `http4s` I will have to end it here and if this blog post gets enough views, I will write a part II.\\n\\nI hope the content was at least mildly interesting and that you didn\u2019t take anything I wrote seriously. Especially type-level programming.\\n\\nMedium link: https://medium.com/virtuslab/data-modeling-in-scala-3-but-i-only-use-types-b6f11ead4c28"},{"id":"Achieving-Indisputable-Job-Security-Using-Novel-Scala-3-Features-A-Case-Study","metadata":{"permalink":"/blog/Achieving-Indisputable-Job-Security-Using-Novel-Scala-3-Features-A-Case-Study","editUrl":"https://github.com/KacperFKorban/kacperfkorban.github.io/blog/2022-02-14-Achieving-Indisputable-Job-Security-Using-Novel-Scala-3-Features-A-Case-Study.md","source":"@site/blog/2022-02-14-Achieving-Indisputable-Job-Security-Using-Novel-Scala-3-Features-A-Case-Study.md","title":"Achieving Indisputable Job Security Using Novel Scala 3 Features: A Case Study","description":"Disclaimer","date":"2022-02-14T00:00:00.000Z","formattedDate":"February 14, 2022","tags":[{"label":"scala","permalink":"/blog/tags/scala"},{"label":"scala 3","permalink":"/blog/tags/scala-3"}],"readingTime":10.77,"truncated":false,"authors":[{"name":"Kacper Korban","url":"https://github.com/KacperFKorban","imageURL":"https://avatars.githubusercontent.com/u/39772805?v=4","key":"k\u03c0"}],"prevItem":{"title":"Data Modeling in Scala 3, but I only use types","permalink":"/blog/Data Modeling in Scala 3, but I only use types"},"nextItem":{"title":"TASTY way of (re)writing macros in Scala 3","permalink":"/blog/TASTY-way-of-rewriting-macros-in-Scala-3"}},"content":"## Disclaimer\\n\\nMost of the article is to be perceived as a joke or satire.\\nThe post is intended as a light read. If you manage to get any educational value from it, you will most likely also enjoy reading the ingredients list of 2% milk.\\nEnjoy!\\n\\n# Intro\\n\\nWe computer programmers frequently state that we code because it is our passion, or because we enjoy building things, or for some other fanciful reason. At the end of the day, though, all Software Engineers write code to make money. This has been on my mind quite a bit lately. So I did some market research and analysis, and after crunching all the figures, I put my findings into this graphic.\\n\\n![](../static/img/job_security_scala/image2.png)\\n\\nThere it is plain and simple. You can clearly see that having a job has a huge impact on the amount of money you make. This is where Scala 3 comes in. We will employ Scala 3 to ensure complete job security. How are we going to do that? It\u2019s easy! By making the code impossible to read. If no one else can maintain, let alone read, our code, we will never get fired!\\nIn this article, I will use the most straightforward programming problems like \u201cHello World\u201d or \u201cisPrime\u201d to demonstrate how you can master this essential skill.\\n\\n### Running the examples\\n\\nThis might be a good time to say that since all the snippets in this blog post are GitHub Gists, you can run them using [scala-cli](https://scala-cli.virtuslab.org/) easily, using the command below.\\n\\n```scala\\n> scala-cli run gist-url\\n```\\n\\n## Hello World\\n\\nOk, let\u2019s start with the best-known coding \u201cproblem\u201d i.e. \u201cHello World\u201d. In Scala 3, the solution to this problem usually looks like this:\\n\\n```scala\\n@main\\ndef main =\\n  println(\\"Hello World\\")\\n```\\n\\n### The good stuff\\n\\nHow do we make this simple code unreadable? Well, instead of writing the code explicitly, we can generate the code that prints the output? Sounds promising! After all, generating code isn\'t easy, right?\\n\\n```scala\\nimport scala.quoted.*\\n\\ninline def helloWorld =\\n  ${ helloWorldImpl }\\n\\ndef helloWorldImpl(using Quotes): Expr[Unit] =\\n  \'{ println(\\"Hello World\\") }\\n```\\n\\nWell, it turns out that it\u2019s really straightforward. We just add an inline method that calls an actual implementation. And the actual implementation is the quoted code from our previous solution.\\n\\n### Abstract tree\\n\\nWe\'ve hit a minor obstacle. How can we get around it?\\nThe biggest problem with our implementation is that what was generated is very obvious as we just quoted our code and spliced it.\\nHow about we disallow quoted blocks then? That way, the generated code will be way more obscure.\\nExactly what do we need to do here? First, we need to return something that is of type `Expr[Unit]` and is semantically equivalent to `{ println(\\"Hello World\\") }`.\\nThe main ways to construct `Expr` are using helper functions in its companion object or creating an (Abstract syntax) `Tree` and converting it to an `Expr`.\\n\\nYeah, right, `Expr\'s and `Tree\'s, we don\'t really care about the semantics. We know that our expression should be the same as quoted `println(\\"Hello World\\")`. So, let\'s do what software developers usually do: put a bunch of `println\'s in random places and hope for the best.\\n\\n```scala\\ndef helloWorldImpl(using Quotes): Expr[Unit] =\\n  println(\'{ println(\\"Hello World\\") }.asTerm)\\n  \'{ () }\\n```\\n\\nAfter running it, at compile time we get:\\n\\n```scala\\nInlined(Ident(helloworldMacro$package$),List(),Apply(Ident(println),List(Literal(Constant(Hello World)))))\\n```\\n\\nWe can ignore the `Inlined` because it means that the term we got was an inlined expression. The exciting part is:\\n\\n```scala\\nApply(Ident(println),List(Literal(Constant(Hello World))))\\n```\\n\\nSo it\u2019s an `Apply` which is a function application of `Ident(println)` to `List(Literal(Constant(Hello World)))`. Great, let\u2019s try recreating it using Quotes API. So, let\u2019s construct an `Apply`, along with \u2018Something\u2019 as the first argument and a list containing a string literal as the second:\\n\\n```scala\\nprivate def helloWorldImpl(using Quotes): Expr[Unit] =\\n  import quotes.reflect.*\\n\\n  val tree = Apply(???, List(Literal(StringConstant(\\"Hello World\\"))))\\n\\n  tree.asExprOf[Unit]\\n```\\n\\nIt\'s a good start, but what about the `???`? Well\u2026 it has to be the reference of `println` and from the definition of `ApplyModule.apply`, it has to be a `Term`. From this, we can imply that what we are looking for is most likely `Ref`, which requires a Symbol.\\n\\n\\nThe Symbol object has methods with a naming pattern beginning with `required`, for example: `requiredClass`, `requiredMethod`, `requiredModule`, `requiredPackage` and so on. Those methods let us \'summon\' symbols of a specific type defined in the compilation unit or on the classpath. Seems great since we want a static method, right? Let\'s try.\\n\\n```scala\\nprivate def helloWorldImpl(using Quotes): Expr[Unit] =\\n  import quotes.reflect.*\\n\\n  val prntln: Ref =\\n    Symbol.requiredMethod(\\"scala.Predef.println\\").pipe(Ref(_))\\n\\n  val tree = Apply(prntln, List(Literal(StringConstant(\\"Hello world\\"))))\\n\\n  tree.asExprOf[Unit]\\n```\\n\\nNote: We use `pipe` here, a function from `scala.util.chaining`. Although the actual implementation is slightly different, it can be thought of like so:\\n\\n```scala\\nextension [A](a: A)\\n  def pipe[B](f: A => B): B = f(a)\\n```\\n\\nIf you see a similarity with `|` bash, then you\u2019re absolutely right. That\u2019s one of the inspirations for it. And If you see a resemblance with `$` or `&` from Haskell, then you should go out more often.\\n\\nRight, we can now run it.\\n\\n```scala\\n[error] ./main.scala:31:3: Exception occurred while executing macro expansion.\\n[error] dotty.tools.dotc.core.TypeError: Failure to disambiguate overloaded reference with\\n[error]   method println in object Predef: (x: Any): Unit  and\\n[error]   method println in object Predef: (): Unit\\n[error] \\tat dotty.tools.dotc.core.Denotations$MultiDenotation.suchThat(Denotations.scala:1244)\\n[error] \\tat dotty.tools.dotc.core.Denotations$Denotation.requiredSymbol(Denotations.scala:297)\\n[error] \\tat dotty.tools.dotc.core.Symbols$.requiredMethod(Symbols.scala:908)\\n[error] \\tat scala.quoted.runtime.impl.QuotesImpl$reflect$Symbol$.requiredMethod(QuotesImpl.scala:2450)\\n[error] \\tat scala.quoted.runtime.impl.QuotesImpl$reflect$Symbol$.requiredMethod(QuotesImpl.scala:2450)\\n[error] \\tat tmp.tmp$package$.helloWorldImpl(tmp.scala:12)\\n[error] \\tat tmp.tmp$package$.inline$helloWorldImpl(tmp.scala:9)\\n```\\n\\nCool, we got some good old-fashioned compiler error, with many references to compiler internals in the stack trace. That\u2019s what we wanted to see.\\nWell, except that after skipping the first line, the message is actually pretty reasonable. There simply are two functions named `println` at this path. And the scaladoc confirms it:\\n\\n![](../static/img/job_security_scala/image1.png)\\n\\nThat means that we cannot solve the problem that easily. But that\u2019s good. The more code, the less readable it becomes. If we cannot access the method itself, let\u2019s access the owner first and get the method from the list of its members. The way we do that is:\\n\\n```scala\\nSymbol.required(\\"scala.Predef\\")\\n```\\n\\nGet its member methods named \u2018println\u2019...\\n\\n```scala\\n  .memberMethod(\\"println\\")\\n```\\n\\nThen filter out the methods with no arguments\u2026\\n\\n```scala\\n  .flatMap { m =>\\n    m.tree match\\n      case defdef: DefDef\\n        if !defdef.paramss.flatMap(_.params).isEmpty => Some(m)\\n      case _ => None\\n  }\\n```\\n\\nAnd finally, just take the `head` of the list and wrap it in `Ref`...\\n\\n```scala\\n  .head.pipe(Ref(_))\\n```\\n\\nCool. So, after composing it into our previous template, we get:\\n\\n```scala\\nprivate def helloWorldImpl(using Quotes): Expr[Unit] =\\n  import quotes.reflect.*\\n\\n  val prntln = Symbol.requiredPackage(\\"scala.Predef\\")\\n    .memberMethod(\\"println\\")\\n    .flatMap { m =>\\n      m.tree match\\n        case defdef: DefDef\\n          if !defdef.paramss.flatMap(_.params).isEmpty => Some(m)\\n        case _ => None\\n    }.head.pipe(Ref(_))\\n\\n  val tree = Apply(prntln, List(Literal(StringConstant(\\"Hello world\\"))))\\n\\n  tree.asExprOf[Unit]\\n```\\n\\nAnd testing it gives us\u2026\\n\\n```\\n> scala-cli run ...\\nHello World\\n```\\n\\nGreat! And just like that, we were able to utilize metaprogramming to write confusing and unmaintainable code.\\n\\n## Not so simple algebra\\n\\nSince we\'ve already done quite a few Hello-Worlds. Let\'s change things up a bit now. Several well-known problems are usually used to learn recursion, e.g. the Fibonacci sequence, factorial, greatest common divisor, is prime, etc. Let\'s pick one at random; let\'s choose is prime.\\n\\nNow you may start asking yourself: \\"How can I really be sure that it\'s actually at random?\\".\\nAnd my answer to you would be: \\"My blog post, my rules. So if I say that it\'s random, then it\'s random, ok?\\"\\n\\n### Vanilla\\n\\nLet\u2019s implement the standard version as a warm-up.\\n\\n```scala\\ndef isPrimeCheat(a: Int): Boolean =\\n  2.until(a).forall(a % _ != 0)\\n```\\n\\nLooks okay, right? RIGHT?! Of course not. I mean\u2026 it correctly checks if a number is prime, I\u2019ll give you that. But we said that it\u2019s an exercise for recursion. And do you see any recursion here? Let\u2019s fix it then.\\n\\n```scala\\ndef isPrime(a: Int, acc: Int = 2): Boolean =\\n  if a <= acc then a == acc\\n  else a % acc != 0 && isPrime(a, acc+1)\\n```\\n\\nSee? It looks better now.\\n\\n### No value calculations\\n\\nNow that the warm-up is over, how do we make this unreadable? How about disallowing the use of values? Sounds great, but can we make it work?\\nThe answer is obviously yes; we can use types.\\nScala 3 has a pretty impressive type system that can operate on singleton types. We can say that the type of `1` is `1` and `1` is a subtype of `Int`. Cool right?\\nWe also know that there is a pretty comprehensive set of type families (functions on type-level) that let us operate on singleton types. This means that we can almost rewrite our standard implementation 1:1. A reasonable attempt will look like this:\\n\\n```scala\\nimport scala.compiletime.ops.int.*\\n\\ntype IsPrime[A <: Int] = IsPrimeRec[A, 2]\\n\\ntype IsPrimeRec[A <: Int, B <: Int] <: Boolean = A <= B match\\n  case true => A == B\\n  case false => A % B != 0 && IsPrimeRec[A, S[B]]\\n```\\n\\nFirst of all, we cannot have default parameters, so we will have to create a proxy function that calls our actual implementation. Then when we look at the actual definition, it is really similar to what we wrote on the value level. The only difference is that we used a match instead of an if statement. And that\u2019s because Scala has match types, but there is no such thing as if-else types.\\n\\nYou might be thinking now: \u201cHold on a sec. How are we going to print the result if it\u2019s a type?\u201d.\\nFirst of all: Ok, smarty-pants. And secondly, we can use the function `constValue` from `scala.compiletime`, which lets us summon values of a given type if the type has a single decidable inhabitant. Like so:\\n\\n```scala\\nimport scala.compiletime.*\\n\\n@main\\ndef main =\\n  println(constValue[IsPrime[13]])\\n  println(constValue[IsPrime[12]])\\n```\\n\\nSo when we run it, we get:\\n\\n```scala\\n> scala-cli run ...\\ntrue\\nfalse\\n```\\n\\nSuccess!\\n\\n### Manual labor\\n\\nWhat did we learn from our exercise just now? Scala 3 makes type-level programming (at least for chosen types) way too easy. Mainly, that\'s because there are so many util functions. That\'s right, you know what\'s coming. Let\u2019s limit our usage of functions from `scala.compiletime.ops.int` to just `S`.\\nIf you don\'t know what `S` does, let me explain. It\'s a type-level successor function for integers. So e.g. S[0] = 1, S[1] = 2 and so on.\\nAnd why did we choose `S` in the first place? That\'s because, together with the literal `0`, it works just like the definition of an inductive set for natural numbers. And since all of our operations are only required to work on natural numbers, we\'re going to implement them that way, so it\'s undefined behaviour for negative numbers.\\n\\nSince the only thing that has to change is the declarations of the helper function, the actual implementation can stay as it was.\\n\\n```scala\\ntype IsPrimeRec[A <: Int, B <: Int] <: Boolean = A <= B match\\n  case true => A == B\\n  case false => A % B != 0 && IsPrimeRec[A, S[B]]\\n```\\n\\nWhat function do we need to implement first? Looks like it\u2019s going to be `<=`. Since we are implementing it for natural numbers, it seems obvious that the implementation has to follow their inductive definition.\\n\\n```scala\\ntype <=[A <: Int, B <: Int] <: Boolean = A match\\n  case 0 => true\\n  case S[a] =>\\n    B match\\n      case 0 => false\\n      case S[b] => a <= b\\n```\\n\\nIt\'s pretty simple:\\n- if `A` is zero then it is smaller or equal to any natural number\\n- otherwise `A` is a successor of any `a`, so:\\n  - if `B` is zero then it cannot be larger or equal than `S[a]`\\n  - otherwise `B` is a successor of any `b` and we check if their predecessors satisfy the predicate.\\n\\nLet\'s do the % next. This one is also pretty simple and looks like this:\\n\\n```scala\\ntype %[A <: Int, B <: Int] <: Int = A < B match\\n  case true => A\\n  case _ => (A - B) % B\\n```\\n\\nNothing exciting going on here. If A is smaller than B, just return B; otherwise, return (A-B) % B.\\n\\nThe rest of the functions are left as an exercise for the reader, but let\u2019s check if it works?\\n\\n```\\n> scala-cli run ...\\ntrue\\nfalse\\n```\\n\\n## Conclusions\\n\\nSo, what did we learn from this article? Mainly that, in Scala 3, even code that\'s meant to be complicated isn\'t actually that bad. And writing unreadable code requires some skill.\\n\\nSo, why not use some of the languages that are unmaintainable by definition, like Rust or Python?\\nIn the case of Rust, it is pretty easy: nobody actually uses Rust; people just like talking about using Rust.\\nAnd when it comes to Python, the problem is that every program in Python is unmaintainable, and we wanted to write code that is readable only to us.\\n\\nMedium link: https://medium.com/virtuslab/achieving-indisputable-job-security-using-novel-scala-3-features-a-case-study-65180eab810a"},{"id":"TASTY-way-of-rewriting-macros-in-Scala-3","metadata":{"permalink":"/blog/TASTY-way-of-rewriting-macros-in-Scala-3","editUrl":"https://github.com/KacperFKorban/kacperfkorban.github.io/blog/2021-04-29-TASTY-way-of-rewriting-macros-in-Scala-3.md","source":"@site/blog/2021-04-29-TASTY-way-of-rewriting-macros-in-Scala-3.md","title":"TASTY way of (re)writing macros in Scala 3","description":"Intro","date":"2021-04-29T00:00:00.000Z","formattedDate":"April 29, 2021","tags":[{"label":"scala","permalink":"/blog/tags/scala"},{"label":"scala 3","permalink":"/blog/tags/scala-3"}],"readingTime":7.425,"truncated":false,"authors":[{"name":"Kacper Korban","url":"https://github.com/KacperFKorban","imageURL":"https://avatars.githubusercontent.com/u/39772805?v=4","key":"k\u03c0"}],"prevItem":{"title":"Achieving Indisputable Job Security Using Novel Scala 3 Features: A Case Study","permalink":"/blog/Achieving-Indisputable-Job-Security-Using-Novel-Scala-3-Features-A-Case-Study"},"nextItem":{"title":"How to write Hoogle for Kotlin in Scala (and Scala.js)","permalink":"/blog/How-to-write-Hoogle-for-Kotlin-in-Scala-and-Scala-js"}},"content":"## Intro\\n\\nIf you have decided to read this blog post, you probably used or at least heard of macros. But just to make sure that we are on the same page: Macros / metaprogramming in Scala provide a way to either generate scala code at compile-time or analyze existing code to gather syntactic data.\\n\\nSince the interface for writing macros in Scala 3 is completely different from that of Scala 2, macro libraries should become easier to develop and maintain. It also means that macro libraries from Scala 2 can\u2019t be easily migrated or ported and instead have to be rewritten using the new TASTY API.\\n\\nThe aim of this blog post is to serve as a manual on efficiently using and navigating through Quotes API (which is the core of metaprogramming), rather than being a migration guide for macros or Scala projects in general. So for some preface/further reading macros documentation can be found [here](https://docs.scala-lang.org/scala3/guides/macros/macros.html) and the migration guide is [here](https://scalacenter.github.io/scala-3-migration-guide/). There is also quite a powerful tool [scala3-migrate](https://github.com/scalacenter/scala3-migrate), which automated most of the migration work.\\n\\nAll code snippets as well as the example mini-project were tested on Scala versions 3.0.0-RC1 and 3.0.0-RC2.\\n\\n## Problem\\n\\nI strongly believe that the best way to learn is by example. So let\u2019s formulate a problem so that we have something to solve (because that\u2019s how real life works). Let\u2019s create a program that for a class (of kind * -> *), generates a neat type description for it, so for a case class like this:\\n\\n```scala\\ncase class NonEmpty[T](e: T, tail: Option[NonEmpty[T]])\\n```\\n\\nwe want to generate a string like this:\\n\\n```scala\\n\\"NonEmpty(e: T, tail: Option[NonEmpty[T]])\\"\\n```\\n\\n## Base\\n\\nLike the title of the article suggests, we are going to be using TASTY reflect. So let\u2019s start by creating an empty object for our code.\\n\\n```scala\\nimport scala.quoted.*\\n\\nobject TypeInfo {\\n inline def apply[T[_]]: String = ${ typeInfoImpl[T] }\\n\\n def typeInfoImpl[T[_]: Type](using Quotes): Expr[String] = {\\n   import quotes.reflect.*\\n\\n   ???\\n }\\n}\\n```\\n\\nLet\u2019s take a look at what is going on here. First, we import scala.quoted.* to have access to Type and Quotes. Then we have the apply method. It only takes a single type parameter because our code isn\u2019t supposed to depend on the value, but rather on the given type. The body of apply is just [spliced](https://dotty.epfl.ch/docs/reference/metaprogramming/macros.html) value of typeInfoImpl. When it comes to typeInfoImpl declaration, it takes the same type parameter and two implicit arguments:\\n- qctx (short for Quotes Context) - gives us access to reflect API\\n- tpe - type information of the type parameter\\nwhile returning a value of type Expr[String], which after splicing yields a String.\\n\\n## Code <3\\n\\nCool, so now that we have a base, we can start writing actual code. Let\u2019s start with something simple, like just getting the class\u2019s name.\\n\\nOur starting point is the tpe value, but in order to get the data we need, we have to transform this Type[T] into something from TASTY reflect. Let\u2019s take a look at the hierarchy in [dotty/Quotes.scala](https://dotty.epfl.ch/api/scala/quoted/Quotes$reflectModule.html) then. The important part is this:\\n\\n```scala\\n+- TypeRepr -+- NamedType -+- TermRef\\n             |             +- TypeRef\\n             +- ConstantType\\n```\\n\\nSo we know that we need a TypeRepr, but in the [Quotes](https://github.com/lampepfl/dotty/blob/main/library/src/scala/quoted/Quotes.scala) file there are no functions that may allow us to do it. That\u2019s because all methods and functions for operating on TASTY types are in [QuotesImpl.scala](https://github.com/lampepfl/dotty/blob/main/compiler/src/scala/quoted/runtime/impl/QuotesImpl.scala). The basic structure in this file is that for every AST node there are three main entries:\\n- type alias for the internal node type\\n- companion object, which implements constructor functions like apply, but also methods like unapply and copy\\n- given with extension methods for our type. The name of this given is always type_name + \u201cMethods\u201d\\nSo the relevant entries for TyprRepr are:\\n\\n```scala\\ntype TypeRepr = dotc.core.Types.Type\\n\\nobject TypeRepr extends TypeReprModule:\\n ...\\n def of[T <: AnyKind](using tp: scala.quoted.Type[T]): TypeRepr =\\n   tp.asInstanceOf[TypeImpl].typeTree.$tpe\\n ...\\nend TypeRepr\\n\\ngiven TypeReprMethods: TypeReprMethods with\\n extension (self: TypeRepr)\\n   ...\\n   def typeSymbol: Symbol = self.typeSymbol\\n   ...\\n end extension\\nend TypeReprMethods\\n```\\n\\nGreat, now we have a TypeRepr. Unfortunately, it doesn\u2019t have any methods that can give us access to the type\u2019s name, to get that information we have to access typeSymbol. After looking through the extension methods in SymbolMethods we can find the method name, which is exactly what we are looking for. Our very much WIP code looks like this:\\n\\n```scala\\nval tpe = TypeRepr.of[T]\\nval name = tpe.typeSymbol.name\\nExpr(name)\\n```\\n\\nNow that we have the basics covered, it\u2019s time to handle value parameters. Once again, we start with tpe of type TypeRepr. We want to access the type declaration, so we have to get typeSymbol. After looking in SymbolMethods for something that can get us case declarations of the class, we can find:\\n\\n```scala\\ndef caseFields: List[Symbol] = ...\\n```\\n\\nWhich does exactly what we want.\\nOur description displays the label and type for every parameter. Getting the label is simple because, just like T\u2019s name, we have a Symbol with the name method. Unfortunately, there is no method that can give us the type of a declaration straight from Symbol. That means we have to look into the AST tree, which can be accessed from Symbol with the method tree (who would have thought :D). Ok, so can we deduce what types of AST nodes are our Symbols? Let\u2019s try, by looking at the hierarchy in [Quotes](https://dotty.epfl.ch/api/scala/quoted/Quotes.html). We can intuitively guess that our case declarations are some kinds of declarations :o. Here is the relevant piece then:\\n\\n```scala\\n+- Definition --+- ClassDef\\n|               +- TypeDef\\n|               +- DefDef\\n|               +- ValDef\\n```\\n\\nLet\u2019s go through all the options one by one:\\n- ClassDef is a definition of a class, so it obviously cannot be a case declaration\\n- TypeDef is a declaration of a type. Type parameters are of type TypeDef, but they aren\u2019t considered case fields\\n- DefDef is a definition of a method, which can\u2019t be a case field either\\n- ValDef is a value definition (or variable)- all case fields are of this type\\nBased on that, we should match on ValDefs. Let\u2019s take a look at the code we have described so far.\\n\\n```scala\\nval caseFields = tpe.typeSymbol.caseFields.map { s =>\\n  val name = s.name\\n  val tpe = s.tree match {\\n    case v: ValDef =>\\n      ???\\n  }\\n  s\\"$name: $tpe\\"\\n}\\n```\\n\\nCool, what can we get from our ValDef then? We don\u2019t have much choice here:\\n\\n```scala\\ngiven ValDefMethods: ValDefMethods with\\n  extension (self: ValDef)\\n    def tpt: TypeTree = self.tpt\\n    def rhs: Option[Term] = optional(self.rhs)\\n  end extension\\nend ValDefMethods\\n```\\n\\nObviously, we want the TypeTree here and after looking at the TypeTreeMethods, there is only one method- tpe: TypeRepr. TypeRepr has a bunch of possible specific types we will have to look into in a second. But for now, let\u2019s do the same trick as we did in the very beginning to get the class name (.typeSymbol.name). Now our code looks like this:\\n\\n```scala\\nval tpe = TypeRepr.of[T]  \\nval name = tpe.typeSymbol.name\\n\\nval caseFields = tpe.typeSymbol.caseFields.map { s =>\\n  val name = s.name\\n  val tpe = s.tree match {\\n    case v: ValDef =>\\n      v.tpt.tpe.typeSymbol.name\\n  }\\n  s\\"$name: $tpe\\"\\n}\\n\\nExpr(\\n  s\\"$name(${caseFields.mkString(\\",\\")})\\"\\n)\\n```\\n\\nAnd it gives this output:\\n\\n```scala\\n\\"NonEmpty(e: T,tail: Option)\\"\\n```\\n\\nLooks almost done. The only thing missing are the type parameters of Option. As I mentioned before, TypeRepr has many specific node types. So let\u2019s take a look at some of them:\\n\\n```scala\\n+- TypeRepr -+- NamedType -+- TermRef\\n            |              +- TypeRef\\n            +- AppliedType\\n            +- AndOrType -+- AndType\\n            |             +- OrType\\n            ...\\n```\\n\\nThere are more of them, so in a real-life scenario, we would have to handle all of them. But my example, my rules. Most of those types are structurally recursive, so will delegate our type extraction logic to a function. For every AST node type we can look for desired methods just like before. For NamedType there is a method name, for AppliedType we can just use unapply to get the tycon (Type Constructor) and args and so on. The result looks like this:\\n\\n```scala\\ndef fullTypeName(tpe: TypeRepr): String = tpe match\\n     case t: NamedType =>\\n       t.name\\n     case o: OrType =>\\n       fullTypeName(o.left) + \\" | \\" + fullTypeName(o.right)\\n     case o: AndType =>\\n       fullTypeName(o.left) + \\" & \\" + fullTypeName(o.right)\\n     case AppliedType(base, args) =>\\n       fullTypeName(base) + args.map(fullTypeName).mkString(\\"[\\", \\",\\", \\"]\\")\\n```\\n\\nAfter using the function call in our main code. The result presents like this:\\n\\n```scala\\n\\"NonEmpty(e: T,tail: Option[NonEmpty[T]])\\"\\n```\\n\\nWhich is exactly what we wanted :D\\n\\n## Takeaways\\n\\nThe examples shown in this article are intentionally straightforward, just to show the basic process of working with TASTY reflect API. But the main ideas I wanted to show are:\\n- Look for node types in [Quotes](https://dotty.epfl.ch/api/scala/quoted/Quotes.html)\\n- Look for implementation and methods in [QuotesImpl](https://github.com/lampepfl/dotty/blob/main/compiler/src/scala/quoted/runtime/impl/QuotesImpl.scala)\\n- Macros in dotty are way easier to write than in Scala 2\\n\\nCode for this example is available [here](https://github.com/KacperFKorban/tasty-macro-migration).\\n\\nMedium link: https://medium.com/virtuslab/tasty-way-of-re-writing-macros-in-scala-3-3ce704a2c37c"},{"id":"How-to-write-Hoogle-for-Kotlin-in-Scala-and-Scala-js","metadata":{"permalink":"/blog/How-to-write-Hoogle-for-Kotlin-in-Scala-and-Scala-js","editUrl":"https://github.com/KacperFKorban/kacperfkorban.github.io/blog/2021-01-14-How-to-write-Hoogle-for-Kotlin-in-Scala-and-Scala-js.md","source":"@site/blog/2021-01-14-How-to-write-Hoogle-for-Kotlin-in-Scala-and-Scala-js.md","title":"How to write Hoogle for Kotlin in Scala (and Scala.js)","description":"Motivation","date":"2021-01-14T00:00:00.000Z","formattedDate":"January 14, 2021","tags":[{"label":"scala","permalink":"/blog/tags/scala"},{"label":"scalajs","permalink":"/blog/tags/scalajs"},{"label":"hoogle","permalink":"/blog/tags/hoogle"},{"label":"kotlin","permalink":"/blog/tags/kotlin"}],"readingTime":8.755,"truncated":false,"authors":[{"name":"Kacper Korban","url":"https://github.com/KacperFKorban","imageURL":"https://avatars.githubusercontent.com/u/39772805?v=4","key":"k\u03c0"},{"name":"Andrzej Ratajczak","url":"https://github.com/BarkingBad","imageURL":"https://avatars.githubusercontent.com/u/32793002?v=4","key":"aratajczak"}],"prevItem":{"title":"TASTY way of (re)writing macros in Scala 3","permalink":"/blog/TASTY-way-of-rewriting-macros-in-Scala-3"}},"content":"## Motivation\\n\\nProgrammers tend to use strongly typed languages for the safety in the runtime and their own comfort while developing applications. While using new dependency, they often have to browse the documentation by symbolic names of classes and functions. Oftentimes, they don\u2019t know the function name, but are convinced there must be a function somewhere that fits given type transformation. In this talk, we will focus on a prototype tool that lets you browse the docs using types as search keys in Kotlin. \\n\\nOnce in a while every developer stumbles upon a code like this:\\n```kotlin\\nval list = listOf(\\"Andrzej\\", \\"Filip\\", \\"Micha\u0142\\")\\nreturn Pair(\\n   list.filter { it.length <= 5 },\\n   list.filter { it.length > 5 }\\n)\\n```\\n\\nAnd then a thought comes in. This looks like something people might do a lot. It surely can be done in a shorter, more readable way. So, what do we know that can help us refactor this code? Well in order to replace this `Pair(list.filter(...), list.filter(...))` we want a function that behaves like this:\\n\\n`<T> List<T>.((T) -> Boolean) -> Pair<List<T>, List<T>>`\\n\\nOk, that\u2019s great, but we still are pretty much nowhere. And that\u2019s because we need this function\u2019s name to call it.\\nHow would we conventionally do it? Well, we could use Dokka for stdlib and look through potential functions, but that can take a lot of time. Plus it is way too close to actual work and we (software developers) don\u2019t really like that.\\nThat\u2019s where Inkuire comes in. Inkuire lets us search a library documentation with function signatures as search keys.\\n\\nOooo, by the way the function we are looking for is `partition`.\\n\\n![](../static/img/writing_hoogle_for_kotlin/image1.png)\\n\\n## Why Scala for Kotlin tooling?\\n\\nOne can wonder: Why are you using Scala for Kotlin tooling? Those are actually two questions framed as one:\\n- \u201cWhy for Kotlin?\u201d - This one is really simple. As software developers we don\u2019t really like doing too much work. In case of gathering Kotlin source data, dokka can do a huge share of work for us. We just need to format the data and persist it. Additionally Kotlin has a way simpler type system than Scala (especially Scala3). Therefore, having Hoogle for Kotlin is like proof of concept for having a similar tool in Scala3 world. \\n- \u201cWhy in Scala?\u201d - The first reason is that Scala is a more mature language. Scala.js has better support and documentation than Kotlin/JS. The other reason is just our personal preference. Scala with the use of Cats and similar libraries allows us to write code in a more functional way and probably everyone can agree, that is the 2020 way to code.\\n\\n## Gathering code data\\n\\nFirst of all, we need a lot of data about code. It\u2019s not plain data from source code but rather complete information about types provided by Kotlin compiler. Therefore we have to analyse sources before we can serialize them. Of course we could use descriptors analysis offered by JetBrains, but there is a more convenient way of doing that thanks to the recently released documentation tool - [dokka](https://github.com/Kotlin/dokka). You can find out more about dokka [here](https://github.com/Kotlin/dokka), but what you have to know is its powerful pluggability abilities that enable you to have all required data about Kotlin and Java sources enclosed in a very simple and intuitive API. \\nIf you would like to use dokka to analyse your own sources, check out this [great article](https://medium.com/virtuslab/analyzing-kotlin-sources-just-got-simpler-48aa88e0cf0b) by Marcin Aman. \\n\\n## Actual search\\n\\nOnce we have the data, it\u2019s time to use it to find our mystery function. The first thing we have to worry about is how to tell the engine what we want, in other words: what should be the format of the query. After reading the title and motivation, it shouldn\u2019t come as a surprise, that we want to search for a function with a specific **signature**, so our input is just going to be a Kotlin signature.\\n\\nThe first step in processing an input string is parsing the given text with a grammar that recognises Kotlin function signatures and then map it to our model. Ironically, searching through scala-parser-combinators with signatures as search keys would be really helpful, since the most commonly used functions from this library are: `^^`, `~`, `~>`, `|`, `<~`, `^^^`. All those seem pretty self explanatory, so I won\u2019t go into much detail about the parser itself. But if you\u2019d like to learn more about using scala-parser-combinators the [getting started](https://github.com/scala/scala-parser-combinators/blob/main/docs/Getting_Started.md) page is a nice starting point.\\n\\nAfter parsing, we have our signature mapped into a more approachable form. So let\u2019s look at our application from the user\'s perspective. If I input a signature, let\u2019s say something like `String.(Int) -> Any`. What functions do I want to see as the result? In other words what should be the relation between our input signature and the result signatures? Well, the easiest and most intuitive relation would be substitution. So for the given signature anything that can be used in its place should be fine. So a function like drop with a signature `String.(Int) -> String` is a good fit, since it has the same input types and just a more specific return type. But a function like maxOf (`Int.(Int) -> Int`) doesn\u2019t fit, because clearly the receiver- `Int` has nothing to do (in terms of subtyping) with the expected receiver `String`.\\n\\n## HTTP Client\\n\\nWhat would be Inkuire without an easily-accessed, user friendly client? The most intuitive and the simplest to deploy on your own is a RESTful service. Inkuire offers a ready to use JAR container that lets you ship the engine locally or globally without much overhead. Graphic design is not our passion, but we did our best.\\n\\n![](../static/img/writing_hoogle_for_kotlin/image2.gif)\\n\\nYou can also try it yourself [here](https://inkuire.herokuapp.com/query).\\n\\n## What if we would like to embed the engine into the documentation itself?\\n\\nImagine that: you configure dokka for your own library. Your code is encouraging to use it functional-programming style, maybe has an ArrowKt as a dependency. You would like to ship your documentation as the HTML pages, but the default search bar in dokka\u2019s default template allows you to search by function names. It would be awesome, if users could browse the documentation using signatures as search keys. We thought the same. So we decided to enable that using Scala.js!\\n\\n## Is it even possible?\\n\\nWell, Scala.js always has been a dark horse of Scala. Many Scala developers remain unaware to these days that Scala.js exists. But it does. And has really good support from community libraries. The idea is: you can transpile your Scala code to JavaScript if all your dependencies can or you depend on stdlib. Luckily, many popular libraries guarantee that compatibility.\\n\\n![](../static/img/writing_hoogle_for_kotlin/image3.gif)\\n\\nYou can try it yourself [here](http://inkuire.s3.eu-central-1.amazonaws.com/master/stdlib/latest/kotlin-stdlib/kotlin-stdlib/index.html).\\n\\n## So how does it work internally?\\n\\nThe querying engine is pure. It has just an input signature and an output list of matching functions. Transpilation to JavaScript is as easy as a piece of cake. The JavaScript obtained from Scala code lets you call the matching function the same way you would call it from standard JVM target. The only thing missing is the way to bind function to the DOM search bar. Luckily, Scala.js provides a DOM API, so you can include all the logic in Scala code without writing a single line of JavaScript by yourself. Isn\u2019t it awesome?\\n\\n## Why Scala.js and not RESTful service?\\n\\nWhy did we decide to transpile the engine code into JavaScript and not use the previously stated RESTful server to delegate calls and present results? Mainly, because we can encapsulate the whole deployment process in one plugin. The user has not to bother with deploying the JAR with the engine. If he could ship docs generated by dokka, he is able to ship them with our plugin attached. This approach also removed the problem with having to update the data for the server with every release. The database is built with documentation, so it will always be in sync with it. The cost of adding the plugin to dokka isn\u2019t that big (memory wise), the JavaScript code itself has only a few MB and e.g. the JVM part of stdlib has 15MB.\\n\\n## Runtime efficiency test of JS and JVM\\n\\nIs it worth using an engine running in your browser instead of a dedicated JVM? Let\u2019s see.\\nThe criteria of the test are: time of engine processing and overall time for the user since he typed the signature till received results. The JVM tests have been conducted using Apache JMeter and JS with Selenium (Chrome runner). The table below shows results:\\n\\n| Platform | Avg engine processing time | Std engine processing time | Avg ovberall time | Std overall time |\\n|----------|----------------------------|----------------------------|-------------------|------------------|\\n| JVM      | 330.26 ms                  | 26.64 ms                   | 332 ms            | 25.65 ms         |\\n| JS       | 1165.57 ms                 | 100.98 ms                  | 2170.31 ms        | 101.43 ms        |\\n\\nAs you can see, the JVM version is about 5 times faster than JS one. The additional 1 second in overall time in JS comes from the debounce time of the input field, so we can detect when the user starts typing. One could think, it\u2019s better to use RESTful service, however, the time latency is so relatively small, it is hard to experience inconvenience from waiting for the results, having the advantage of jumping directly to the exact documentation subpage.\\n\\n## What if I would like to use it myself?\\n\\nCurrently, we do not publish artifacts to remote repositories. If you would like to use Inkuire for your project here source code. Installation guide can be found in [readme](https://github.com/VirtusLab/Inkuire/blob/kotlin/README.md). Note that Inkuire has two main drawbacks. One is not a fully integrated multiplatform - you have to choose arbitrarily which source sets you would like to query from. Also, there is still the problem with getting a full hierarchy tree of types declared in dependencies. The rule of thumb is the same as with Scala.js: To obtain a full hierarchy tree, you must provide types databases from all dependencies. We know that going recursively deeper in the dependencies tree and generating all types databases is a tedious job, but it\u2019s the only solution available right now. However, using a type database only for a given library will cause engine work heuristicly; it will give true and applicable results, though he won\u2019t see all possible substitutions, and you will not be able to use types that you know are higher in the inheritance tree.\\n\\nMedium link: https://medium.com/virtuslab/how-to-write-hoogle-for-kotlin-in-scala-and-scala-js-8c98c1c303ff"}]}')}}]);